\label{cha:reflection}
This chapter contains the reflections on the topics covered in this thesis. Each paragraph is initiated with a title, that describes the covered topic. 

\section*{Related works}
\subsection*{Predicting the Thesis Result}
During the investigation of related works, it became clear that there was no single configuration that the frameworks adhered to. This was true in regards to requirements for run-time and compilers, but also for their way of handling anonymous functions. The most challenging technical problem of this project is to support anonymous functions, and as every related work handles this topic differently, it could be considered a warning; that this would become a big challenge. Instead of investigating further how to handle anonymous functions in general, we decided to focus the development effort on exploring the combination of run-time and compiler-dependent/compiler-independent choice combination not seen in the related works. This mean that the effort went to making \textit{YAGAL} a compiler-independent framework running on top of the \textit{CUDA Driver API}, which also supports a new abstraction regarding how to build and execute kernels, while experimenting with integrating \textit{LLVM} in such a framework. This decision led to us trying to solve too many challenges simultaneously, where only a subset of the challenges was accomplished. A delimitation of the problem could have been beneficial for the project, to steer the focus.

\section*{Design}
\subsection*{API First or Architecture First}
Designing the API first, and then an architecture to fit it, worked out as expected. It may have been at the cost of how the underlying architecture is presented to the developer, but it was convenient to have a set of features needed by the API to design the architecture towards.

\subsection*{The Fit of the Action and Execution Abstractions}
The abstraction we created to cover kernels was the concept of actions, where a kernel can be constructed by putting together a chain of commands, was a different approach to the usual kernel definition model. We were inspired to take a different approach to this, as we saw both \textit{SkelCL} with its algorithm skeletons, and \textit{PACXX} presenting lazy evaluation in a paper\cite{lazyPacxx}. We found the action model to be simpler to comprehend, compared to the usually more explicit definition of kernels. It is not without issues, and it can be very verbose to express simple kernels when nesting calculations. The abstraction is interesting, and there might be problems where this approach can be a better fit than GPU kernel development.

\subsection*{The Fit of the Vector Abstraction}
The abstraction we created to cover memory allocation was the \textit{YAGAL} vector. It was designed to be deliberately different from \textit{STL}s vector, while being compatible with it through copy constructor and casting. This resulted in a construction that controlled allocation and copies between data and device, through a single interface. This abstraction was convenient, and could be used as a base for a matrix construction in the future.

\section*{Choice of Framework Technologies}
\subsection*{Not Developing YAGAL as a Compiler}
The decision to not implement \textit{YAGAL} as a compiler, but rather as a library, was interesting. The only related works that did this was based on \textit{OpenCL}, which we chose to differ from, and \textit{Thrust} which required \textit{NVIDIA}s compiler. The problems we encountered might have been easier to solve if we could build a compiler to read the lambdas, and possibly even introduce new keywords to the language that could identify device functions, like \textit{Thrust} does it with \texttt{\_\_device\_\_}. While it could solve some problems, it would also be less interesting, as it would not have served the purpose of exploring the field of compiler-independent GPGPU frameworks.  

\subsection*{Choosing CUDA over OpenCL}
The decision to base the solution on the \textit{CUDA Driver API} was another interesting one. The related works, that are compiler-independent, are building the kernels as \textit{OpenCL} code strings, so with \textit{YAGAL} we attempted a new approach for a compiler-independent solution. Targeting \textit{PTX} as the code language was done as it is executable by the \textit{CUDA Driver API}, and \textit{LLVM} supports it as a back-end for its code generators. If \textit{YAGAL} was targetting \textit{OpenCL}, we would probably have progressed further in development, but it would have impacted the novelty of the project, as there already exist other compiler-independent frameworks that target \textit{OpenCL}, those being \textit{Bolt} and \textit{SkelCL}. As the goals we attempt to accomplish simultaneously with \textit{YAGAL} have been plenty, this could still be argued a better choice.

\subsection*{Using LLVM}
The decision to use \textit{LLVM} was inspired by \textit{PACXX}, as they use the \textit{PTX} back-end of \textit{LLVM} to generate \textit{PTX} code. As \textit{YAGAL} is implemented as a library, we saw an opportunity in utilizing \textit{LLVM} for code generation at run-time. This was done by including the necessary components of \textit{LLVM} in \textit{YAGAL}, as code that would get compiled into the final executable keeping \textit{YAGAL} compiler independent. \textit{LLVM} is meant for compiler construction, and the experience of using it outside of that domain was interesting, as documentation was directed at compiler construction. With \textit{LLVM} we got the \textit{LLVM Intermediate Representation}. It provided us with a higher level of expressiveness compared to \textit{PTX}. This expressiveness combined with the many features \textit{LLVM} brings in regards to code generation and optimization was a great benefit. Generally, the use of \textit{LLVM} has been a learning experience, where we took a well established framework for one domain, namely compiler creation, and adopted it to another.

\section*{Implementation}
%\todo{chaning of actions are pretty neat?}
%The notion of putting together multiple actions in a single kernel is interesting. It was one of the features where the inclusion of \textit{LLVM} proved its worth by doing optimizations on the generated code. Without the ability to put together multiple actions in a single kernel, the generated code would be very inefficient, such as multiple loads and stores of the same values in sequences. Without chaining of actions it would be hard to argue that \textit{LLVM} is worth using.

\subsection*{Replacing LLC}
We chose to make a re-implementation of the \textit{LLVM} tool \textit{LLC} as a part of \textit{YAGAL}. \textit{LLC} is the tool used to translate \textit{LLVM Intermediate Representation} to the various targets \textit{LLVM} supports, including \textit{PTX}. We did this to make the executable, that is built with \textit{YAGAL}, avoid interaction with other processes as much as possible due to performance and to be self contained. We did not perform performance measurements to ensure the necessity of this, which could have been interesting to see. We are, however, confident that performing the translations in memory is faster than outputting intermediate code and running an external process, that may or may not be present on the executing system, to get the same effect.

\subsection*{The Compilation Time}
One of the problems of \textit{YAGAL} is the long compilation time; for the \textit{SAXPY} example it took 43 seconds, which is a long time for such a simple program. The compilation time is mainly due to the inclusion of large parts of the \textit{LLVM} library. This could possibly have been worked around with a smarter compilation chain compared to linking everything in a single translation unit, as we did. We chose not to focus much on this problem during development, as we valued other features higher during our development time. This might be worth investigating at a later point, but there are still more pressing issues.

\subsection*{Anonymous Functions}
Another more functionality impairing problem is the lack of anonymous functions. We consider the difficulty of providing this feature a product of the early design decisions, as we did not expect the choice of being compiler-independent without relying on \textit{OpenCL} to hinder the implementation. This could have been avoided if we had taken these decisions after getting a better understanding of how they would impact the implementation of anonymous functions.

\subsection*{The exportPtx Conflict}
We decided to have support for loading external \textit{PTX} for execution, and as a natural continuity on this we also wanted to allow the user to export the \textit{PTX} that the developer had constructed using \textit{YAGAL}s actions. This gave some benefits, such as being able to generate kernels at one point and executing them later, and giving the developer the option to not repeatedly generate the same kernel for multiple executions of the same logic. But the benefits came at the price of divulging the inner components of the framework, and hurting the consistency of our abstractions.

\section*{Evaluation}
\subsection*{Involving More People in Evaluation}
The evaluation of \textit{YAGAL} was done by us. This is not ideal, as we have understanding of the frameworks inner mechanism, where another person would have a less biased view on it. As we treat \textit{YAGAL} to be an experiment, we do consider the current evaluation to be sufficient as a method of showing the current state of the system. However, for getting a fair evaluation that avoid bias, more people should be involved.

\subsection*{SAXPY as Example}
Another critical point of the evaluation is the implemented algorithm. We chose to implement \textit{SAXPY}, as it is within what is currently possible with \textit{YAGAL}. Comparing \textit{YAGAL} based on performance or any other metric against others is not fair, as the other frameworks can implement much more advanced algorithms than \textit{YAGAL}. Other algorithms of increasing complexity should be used to get a more fair impression.
