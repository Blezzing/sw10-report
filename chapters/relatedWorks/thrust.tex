\section{Thrust}
\textit{Thrust} is a \textit{C++} library that allow developers to implement high performance applications with minimal programming effort. This section is based on \textit{Thrust}'s overview document\cite{thrustOverview} and \textit{Github} page\cite{thrustGithub}.

\subsection{Goals}
The aim of \textit{Thrust} is to make high performance application development as easy as possible. It is designed to be similar to \textit{STL}, with the intention of being concise, readable, and efficient. It is intended to supply the developers with containers and fundamental algorithms, with user defined behavior, rather than specific numeric algorithms as provided by \textit{BLAS}. It is also intended to be interoperable with \textit{CUDA}.

\subsection{Programming Model}
\textit{Thrust} is modeled on \textit{STL} and as such, follows the model of calling functions with iterators as arguments to instruct where input, and output is located.

Listing \ref{code:thrustSaxpy} shows how the \textit{SAXPY} computation can be implemented in \textit{Thrust}, and the usage of iterators to manage data access is shown.

The execution of \textit{SAXPY} is done in line \ref{code:thrustSaxpy:execute}, and shows how iterators are used to define input and output locations.
\begin{lstlisting}[caption={\textit{Thrust} \textit{SAXPY} example.}, label={code:thrustSaxpy}]
size_t N = 1024;
int a = 10;

//cuda classifier on lambda
auto func = [=]__device__(int x, int y){return a * x + y;};

//initialize host vectors
thrust::host_vector<int> x(N);
thrust::host_vector<int> y(N);
thrust::host_vector<int> z(N);

//fill with random data
std::generate(x.begin(), x.end(), rand);
std::generate(y.begin(), y.end(), rand);

//copy to device
thrust::device_vector<int> d_x = x;
thrust::device_vector<int> d_y = y;

//perform saxpy
thrust::transform(d_x.begin(), d_x.end(), d_y.begin(), d_y.begin(), func); ~\label{code:thrustSaxpy:execute}~

//copy results back to host vector
z = d_y;
\end{lstlisting}

\subsection{Implementation}
\textit{Thrust} is a library build on top of the \textit{CUDA} library. This means that the developer will include the \textit{Thrust} header files needed, and compile her program with the \textit{NVIDIA} compiler, \textit{nvcc}, as seen on \ref{fig:thrustCompilation}. The compilation process is fully static, and results in a single executable with both host and device code included.
\begin{figure}
\center
\includegraphics[width=0.8\textwidth]{chapters/relatedWorks/figures/thrust_compilation.png}
\caption{Thrust Compilation Process.}
\label{fig:thrustCompilation}
\end{figure}

\subsection{Key Points}
The API of \textit{Thrust} is structured to imitate that of \textit{STL}, and a \textit{C++} developer is therefore familiar with it. It can be very verbose with multiple operations on the same container since the usage of the containers is based on iterators.

\textit{Thrust} is a header only implementation, meaning there is no need for a specialized compiler, and it builds upon \textit{CUDA}. This allows mixing \textit{Thrust} and \textit{CUDA} code if there is a need for specialized code.