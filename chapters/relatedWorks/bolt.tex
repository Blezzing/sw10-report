\section{Bolt}
\textit{Bolt} is a library providing abstractions for heterogeneous computing. This section is based on \textit{Bolt}'s documentation\cite{boltDoc} and \textit{Github} page\cite{boltGithub}.

\subsection{Goals}
The aim of \textit{Bolt} is to provide high performance library implementations for common algorithms, following the structure of \textit{STL}. It is intended to make heterogeneous development easier, and is designed to provide an application that can execute on either a CPU or any OpenCL capable unit.

\subsection{Programming Model}
\textit{Bolt} is modeled on \textit{STL} and as such, follows the model of calling functions with iterators as arguments to instruct where input and output is located.

\textit{Bolt} provide functions for modifying \textit{STL} containers, and the library determines whether the computation should happen on host or device, involving any required copying.

The example shown in Listing \ref{code:boltSaxpy}, shows how well the library interfaces with an \textit{STL} vector.

From line \ref{code:boltSaxpy:cppamp} until the next comment it is shown how the function is defined and implemented with the \textit{C++ AMP} backend. It is done with a \textit{C++11} lambda and \textit{C++ AMP}'s restrict classifier.

From line \ref{code:boltSaxpy:opencl} it is shown how, instead of a lambda, a functor is needed when using the \textit{OpenCL} backend. The functor is then defined inside a BOLT\_FUNCTOR macro to statically generate relevant \textit{OpenCL} code.

\begin{lstlisting}[caption={Bolt \textit{SAXPY} example}, label={code:boltSaxpy}]
const size_t N = 1024;
int a = 10;

std::vector<int> x(N);
std::vector<int> y(N);
std::vector<int> z(N);

std::generate(x.begin(), x.end(), rand);
std::generate(y.begin(), y.end(), rand);

//bolt with c++ amp backend ~\label{code:boltSaxpy:cppamp}~
auto saxpyLambda = [=] (float xx, float yy) restrict(cpu,amp) {
  return a * xx + yy;
};
bolt::transform(x.begin(), x.end(), y.begin(), z.begin, saxpyLambda);

//bolt with opencl backend ~\label{code:boltSaxpy:opencl}~
BOLT_FUNCTOR(SaxpyFunctor,
  struct SaxpyFunctor{
    int _a;
    SaxpyFunctor(int a): _a(a) {};
    float operator() (const int& xx, const int& yy){
      return _a * xx + yy;
    };
  };
);
boltcl::transform(x.begin(), x.end(), y.begin(), z.begin, SaxpyFunctor(a));
\end{lstlisting}

\subsection{Implementation}
% Intro / Overview
\textit{Bolt} is an includeable library with two possible backends, namely \textit{C++ AMP} and \textit{OpenCL}.  

% Memory / Types
\textit{Bolt} have made an effort to integrate into the regular STL of C++. To this end, data is managed within regular host memory data types, such as vectors. Before any data are used on the GPU, \textit{Bolt} will copy the data to device and back once the kernel has executed. \textit{Bolt} also provide device specific types such as \texttt{device\_vector} which allocates data directly in device memory, but the performance provided by these are when the data are used within multiple kernel calls since it do not need to be copied to device upon text use.

% Kernels / func
Lambda expressions is used to express kernel functions when \textit{C++ AMP} is the targeted backend. The procedure is similar to how it is done in \textit{C++ AMP} which is described in Section \ref{cha:cppAmpRelWork}, but \textit{Bolt} will handle the interaction with data and the \texttt{array\_view}s of \textit{C++ AMP} is therefore not needed. The \texttt{restricted} keyword is still used to tell the compiler that only a subset of functionality is available within the lambda scope.

Functors are used to express kernel functions when using \textit{OpenCl} as the targeted backend. A functor allows the construction of a struct that can be called as a regular function. 

% Comp / Figref
One of the two supported backends are \textit{C++ AMP}, and the compilation chain can be seen on Figure \ref{fig:boltAmpCompilation}. Here the user code have included the Bolt headers which in turn makes use if the \textit{C++ AMP} headers. \textit{MVSC} is used for compilation since its the only compiler that supports \textit{C++ AMP}. This results in an executable file that utilizes \textit{Direct 3D} for execution on the GPU.

\begin{figure}[H]
\center
\includegraphics[width=0.8\textwidth]{chapters/relatedWorks/figures/bolt_cl_compilation.png}
\caption{Bolt Targeting OpenCL Compilation Process.}
\label{fig:boltClCompilation}
\end{figure}

The other of the two supported backends are \textit{OpenCL}, and the compilation chain can be seen on Figure \ref{fig:boltClCompilation}. It is the same procedure as it was with \textit{C++ AMP}, except that \textit{Bolt} will make use of OpenCL headers, it is not dependent upon the \textit{MVSC} compiler, and it will utilize the OpenCL runtime.

\begin{figure}
\center
\includegraphics[width=0.8\textwidth]{chapters/relatedWorks/figures/bolt_amp_compilation.png}
\caption{Bolt Targeting C++ AMP Compilation Process.}
\label{fig:boltAmpCompilation}
\end{figure}

\subsection{Key Points}
Being able to use the same algorithms on both \textit{STL} containers, and \textit{Bolts} containers can provide an easier transition.

Being a library on top of other frameworks results in some code artifacts. With \textit{C++ AMP} as target, the use of the restrict classifier on lambdas seem unergonomic. \texttt{BOLT\_FUNCTOR} as a macro is used to overcome the language gap between \textit{C++} and \textit{OpenCL C} when \textit{OpenCL} is set as targeted backend. Both examples show that workarounds to support the target backend sometimes will show up in the API. 

The usage of the containers is based on iterators, as \textit{STL} is, and can be very verbose with multiple operations on the same container.
