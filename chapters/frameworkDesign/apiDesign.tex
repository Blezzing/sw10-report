\section{API Design}
\subsection{Goals}
%vi ønsker at abstrahere væk fra kernels, none of related works use kernels as abstraction
We want a developer to be able to use high level functional abstractions such as map and reduce, without writing specific kernel functions for every appliance. The kernel model in general requires the developer to handle threads, thread blocks and work distribution, which is a part of the learning requirement, that we want the spare the developer of.
As such we want the API to have a set of high order functions available to the developer, and not expose any kernel logic that she is not yet prepared for.

%vær kompatibel med cuda, thrust er rigtig gode til dette
We want the API to be replaced by more specific implementations written in \textit{CUDA}, as such it is preferred that the API allows an easier transition, by allowing interfacing with \textit{CUDA}.

\subsection{Data types}
\todo{vi laver nogle data typer der indkapsler brug og data: arrays (ingen related), vectors(alle related), multidims(cppamp views)} 

\todo{skal de tilgås som stl containers(.begin() og .end())? ranges(bare .)? kompatibilitet med cuda(raw ptr)?}

We want to provide a developer with types that makes it convenient to work with the GPU. It is difficult to define what makes types accessible and easy to work with since there are multiple factors in play, such as the context of the programming language, the context of application, and what an individual developer sees as convenient. In this section and subsections, we explore some of these factors in the form of memory model, the actual data types, how types are accessed, and compatibility degree for CUDA, in order to determine how the types of \textit{YAGAL} should be designed.

\subsubsection{Memory model}
% where is the data
There are two ways of handling the underlying memory of \textit{YAGAL}s data types in our opinion. Either the data types are unified such that \textit{YAGAL} handles memory transfers between host and device implicitly, or provide a ways for a developer to transfer the data on their own accord. 

% Handle memory implicitly - Bolt and PACXX
In the case of \textit{YAGAL} being able to handle memory transfers between host and device implicitly, data should here be available and behave as regular \textit{STL} data types when used on host, and be available for use on device. \textit{Bolt} and \textit{PACXX} handles memory this way, as seen in Chapter \ref{cha:relatedWorks}. The main advantage of this approach is that a developer does not need to be concerned about memory when working with \textit{YAGAL}. A downside is that it may create difficulties for a developer when they want to replace \textit{YAGAL} with \textit{CUDA}.

% Provide methods for memory handling - Thrust, AMP, and SkelCL
Memory in \textit{C++} is handled explicitly, and an experienced \textit{C++} developer is used to know and be in control of how and where data is stored. As \textit{YAGAL} is a \textit{C++} library, it makes sense to let developers handle memory themselves. Therefore it would make sense for \textit{YAGAL} to facilitate ways to manually manage where data is allocated and be able to control transfers between host and device. In Chapter \ref{cha:relatedWorks} we saw that \textit{Thrust}, \textit{C++ AMP}, and \textit{SkelCL} handles memory this way.

% The decision
We decided that \textit{YAGAL} will provide developers with the means to manage allocation and transfers of data between host and device themselves, instead of handling it implicitly.

\subsubsection{the types}
% Introduction to considered types
There are many types that \textit{YAGAL} could potentially provide. To stay within the deadline limit of this project, we decided to keep the amount of provided types to a minimum, and extend \textit{YAGAL} with additional types if it can be completed before the deadline. The types we considered are \texttt{arrays}, \texttt{vectors}, and \texttt{maps}.

% We would like vectors, but arrays if it fails
The frameworks in \ref{cha:relatedWorks} all provide \texttt{vectors} with the exception of \textit{C++ AMP} that uses \texttt{arrays} and \texttt{array\_views}. Based on this, we would like \textit{YAGAL} to support \texttt{vectors}, but it is unclear to what degree of complications the implementation of \texttt{vectors} would introduce. \texttt{arrays} on the other hand, appear to be more simple to implement. As such, since we have decided to go with an implementation first approach, we will attempt to implement \texttt{vectors} and have \texttt{arrays} as fallback.

% Multi dim support
In regard to multidimensional support for \texttt{vectors} and/or \texttt{arrays}, i depends on the deadline. We would like \textit{YAGAL} to support it, but it is not a priority.

% No support for maps
The \texttt{map} data container is an interesting option, since the GPU could be utilized to perform lookups. We see this as out of scope in regard to the aim of \textit{YAGAL}.

\subsubsection{CUDA compatibility}
\todo{todo}

\subsection{Functions}
\todo{vi laver nogle højniveau funktioner, functors vs lambdas, chaining, vi kan snakke om mulighed for "collapsing", .execute()?}
\todo{gennemgå hvilke funktioner vi mener der er nødvendige}
\todo{map, reduce, filter, zip, access}
\todo{hvordan tager vi imod lambdaer}
