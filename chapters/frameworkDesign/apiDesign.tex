\section{API Design}
In this section we discuss the design of the API, and the reasoning that behind to these decisions.

\subsection{Goals}
As it is stated in the motivation in Section \ref{cha:motivation}, we want to prioritize high abstraction over absolute performance. W want to avoid exposing kernel logic and put a layer of abstraction upon the general GPU model by handling kernel function setup and setup of blocks and threads for the developer.

In Section \ref{cha:languageSelection} it is stated that we want the API to be replaceable by more specific implementations written in \textit{CUDA}, as such it is preferred that the API allows an easier transition, by allowing interfacing with \textit{CUDA}.

There are multiple ways of achieving a higher level of abstraction and multiple ways of interfacing with \textit{CUDA}. In the following sections we discuss some of the options and decisions taken in designing \textit{YAGAL}.

\subsection{Data types}
We want to provide a developer with types that makes it convenient to work with the GPU. It is difficult to define what makes types accessible and easy to work with since there are multiple factors in play, such as the context of the programming language, the context of application, and what an individual developer sees as convenient. In this section and subsections, we explore some of these factors in the form of memory model, the actual data types, how types are accessed, and compatibility degree for CUDA, in order to determine how the types of \textit{YAGAL} should be designed.

\subsubsection{Memory Model} \label{memoryModelDesign}
% where is the data
Two general directions of handling the underlying memory of \textit{YAGAL}s data types. One is that the data types represent a unified memory layout, where the actual location of the data is handled by \textit{YAGAL}, involving any data transfers required to perform computations. The other is to provide methods for a developer to control the location of the data, giving her more work, but more explicit control. 

% Handle memory implicitly - Bolt and PACXX
In the case of \textit{YAGAL} being able to handle memory transfers between host and device implicitly, data should be available and behave as regular \textit{STL} data types when used on host, and be available for use on device. \textit{Bolt} and \textit{PACXX} handle memory this way, as seen in Chapter \ref{cha:relatedWorks}. An advantage of this approach is that a developer does not need to be concerned about memory when working with \textit{YAGAL}. A downside is that the developer loses control of when transfers are happening, which can come at a high performance cost. It may also create difficulties for a developer when she want to replace \textit{YAGAL} with \textit{CUDA}.

% Provide methods for memory handling - Thrust, AMP, and SkelCL
Memory in \textit{C++} is handled explicitly, and an experienced \textit{C++} developer is used to know and be in control of how and where data is stored. As \textit{YAGAL} is a \textit{C++} library, it makes sense to let developers handle memory themselves. Based on this we decided that \textit{YAGAL} will facilitate ways to manually manage where data is allocated and be able to control transfers between host and device. In Chapter \ref{cha:relatedWorks} we saw that \textit{Thrust}, \textit{C++ AMP}, and \textit{SkelCL} handles memory this way.

% The decision
We decided that \textit{YAGAL} will provide developers with the means to manage allocation and transfers of data between host and device themselves, instead of handling it implicitly.

\subsubsection{Supported Types}
% Introduction to considered types
There are many types that \textit{YAGAL} potentially can provide. To stay within the time frame of this project, we decide to keep the current amount of provided types to a minimum, and extend \textit{YAGAL} with additional types depending on the deadline. The types we have considered are \texttt{arrays}, \texttt{vectors}, and \texttt{maps}.

% We would like vectors, but arrays if it fails
\texttt{vectors} are contiguous memory that can be used as arrays with the possibility of being dynamically resized, in contrast to \texttt{arrays} which are contiguous memory with a static size. The frameworks in Chapter \ref{cha:relatedWorks} all provide \texttt{vectors} with the exception of \textit{C++ AMP} that uses \texttt{arrays} and \texttt{array\_views}. Based on this, we want \textit{YAGAL} to support \texttt{vectors}, but it is unclear to what degree of complications the implementation of \texttt{vectors} would introduce, due to their dynamic functionality. \texttt{arrays} on the other hand, appear to be more simple to implement due to them being statically sized. We will therefore focus on implementing \texttt{vectors} and have \texttt{arrays} as fallback solution, as the possibility of being able to dynamically resize a data collection is a quality that makes it easier for developers to use.

% Multi dim support
In regard to multidimensional support for \texttt{vectors} and/or \texttt{arrays}, it is convenient to have as it makes some tasks easier to implement, but it is of low priority as it is a more specialized feature, that is not needed by all developers, in contrast to single dimension arrays or vectors. We would useful for \textit{YAGAL} to support it, but it will not be prioritized.

% No support for maps
The \texttt{map} data container is an interesting option, since the GPU could be utilized to perform lookups. This however does not contribute to the overall goal of \textit{YAGAL}, as we have not observed this feature in any of the tools covered in chapter \ref{cha:relatedWorks} and the introduction of this feature does not contribute to \textit{YAGAL} being replaceable. \texttt{map} will therefore not be supported.

\subsubsection{Accessing Data}
When a data container is in use, there are multiple possible methods of accessing the data that can be expected. 

When a single element is required, either for read or write, we consider two options:
\begin{itemize}
\item Using \texttt{container.get(index)} and \texttt{container.set(index, value)} to read and modify.
\item Using \texttt{container[index]} to read and modify.
\end{itemize}
We chose to implement get and set functions, as the square bracket accessing can be developed on top of these at a later point if needed.

It is more problematic when more than a single element is needed. There are multiple options we consider:
\begin{itemize}
\item Providing iterators to provide iteration over data, as is tradition in \textit{C++}.
\item Providing a pointer to the first element and a number of elements to let a developer control access, as is tradition in \textit{C}.
\item Providing the number of elements to let the developer use single element accessing methods.
\item Providing casting rules to let a developer cast a collection to another type that provides the needed accessing methods at the cost of a data transfer to host.
\end{itemize}
We chose to provide a developer with the device pointer to the data, and the number of elements contained, giving the developer information enough to use the single element accessors. This also allow direct access to the memory for other frameworks if multiple frameworks are used together.

Providing iterators is problematic as it motivates the developer to make many small copies back and forth between device and host. Instead we chose to provide a method to create a \textit{STL} vector with a copy of the device data, which will provide iterators for the copy. The copy can then be copied back to the device, and as such only need two transfers, which compared to two transfers per element is more convenient.

\subsection{Functions}
To let a developer use \textit{YAGAL} we need some functions to provide the needed functionality. We chose to experiment with a different function structure compared to the related works in chapter \ref{cha:relatedWorks}. Where the related works generally define some kind of kernel function, and then applies it to a collection, we want to build the kernel on the collection in an attempt to make the process more readable.

\subsubsection{Calling execute on a collection}
% Principle
A way to achieve building a kernel upon the collection could be by doing it lazily. A developer could build up kernel functionality by appending functions upon the collection. When the developer have applied her functions, then the actual kernel function would be generated and executed based on the stored functions, when she calls execute on the collection.

% Pros
An advantage of this approach is that it could prevent unnecessary data transfers between host and device since it might be possible to bundle necessary logic within a single kernel function. 

% Cons 
A disadvantage of this approach is that it could be a cause for confusion for the developer. When the developer applies \texttt{add(5)} to a collection, a developer might expect the addition to have already taken place.

\subsubsection{Function Chaining}
We want to make a single kernel able to execute multiple actions, such as adding and multiplying a value in sequence. To enable this we want each function call to return a reference to the collection object so that multiple actions can be queued before the final execute call.

This will allow a program, that adds 5 to all elements of a collection before multiplying them with 2, in \textit{YAGAL} to be written as \texttt{collection.add(5).multiply(2).exec()}, which we find to be very intuitive to read in comparison to the define kernel and apply kernel form of the other frameworks.

Allowing chaining of functions also allow the framework to make decisions on how to split kernels, so that the example above would result in executing a single kernel doing both actions, rather than executing an add kernel and a multiply kernel in sequence.

\subsubsection{?}
\todo{Hvilke low order functions vil vi have}

\subsubsection{?}
\todo{Hvilke high order functions vil vi have}
